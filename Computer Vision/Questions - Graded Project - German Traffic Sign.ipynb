{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Questions - Graded Project - German Traffic Sign.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9jAqShELHZI"
      },
      "source": [
        "![alt text](https://drive.google.com/uc?export=view&id=1UXScsVx_Wni_JuDdB8LeTnM6jsPfIwkW)\n",
        "\n",
        "Proprietary content. © Great Learning. All Rights Reserved. Unauthorized use or distribution prohibited."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRkFT8HtCZHS"
      },
      "source": [
        "# German Traffic Sign Recognition\n",
        "Multi-class, single-image classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJWdbMALTcGJ"
      },
      "source": [
        "### Dataset\n",
        "The German Traffic Sign Benchmark is a multi-class, single-image classification challenge held at the International Joint Conference on Neural Networks (IJCNN) 2011. They cordially invite researchers from relevant fields to participate: The competition is designed to allow for participation without special domain knowledge. Their benchmark has the following properties:\n",
        "\n",
        "- Single-image, multi-class classification problem\n",
        "- More than 40 classes\n",
        "- More than 50,000 images in total\n",
        "- Large, lifelike database"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hRhJulWyIGMN"
      },
      "source": [
        "#### Notes\n",
        "- For this project, we have reduced the number of images. There are around 16,500+ images in the dataset provided. You can check “label_details” folder for getting information about the classes.\n",
        "- If the model is taking too much time to get trained then you can reduce the number of classes. There are around 43 classes in the dataset, model should be trained on a minimum of 15 classes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qC37j3FUDVYd"
      },
      "source": [
        "### Initialize ImageDataGenerator (7 Marks)\n",
        "- Rescale the images\n",
        "- Specify value for validation_split & get 75% data in training and 25% data in training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OakETLlCBwy1"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdlsyi7nR2Op",
        "outputId": "76978469-f763-4dc7-be66-2e125f0e38d6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUxALQp_dhpR",
        "outputId": "d907c6fc-07ec-40c9-fb17-52be7f6c48b5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YPv86XQaWumC"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    featurewise_center=True,\n",
        "    validation_split=0.25,\n",
        "    horizontal_flip=True)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58e4ODapEVdx"
      },
      "source": [
        "### Get training data from ImageDataGenerator (5 Marks)\n",
        "- Give directory path\n",
        "- Give target size\n",
        "- Give batch_size\n",
        "- Specify classes, if you wish to use less number of classes you need to give class names in a list (Atleast 15 classes should be there)\n",
        "- Specify class_mode\n",
        "- Specify color_mode\n",
        "- Specify subset\n",
        "\n",
        "You can get details here\n",
        "https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXrSxu9WSwMK",
        "outputId": "ff25b935-0542-4782-e69b-5824e3fbc171",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_generator = datagen.flow_from_directory(\n",
        "    '/content/drive/My Drive/Data - German Traffic Sign Recognition/Train',\n",
        "    target_size=(128, 128),\n",
        "    batch_size=64,\n",
        "    classes=['20','21','22','23','24','25','26','27','28','29','30','31','32','33','34','35'],\n",
        "    class_mode='categorical',\n",
        "    subset='training')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 6595 images belonging to 16 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSfT2cB4COgC"
      },
      "source": [
        ""
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ds68yCB0UJKt"
      },
      "source": [
        ""
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WehEClL1UUP9"
      },
      "source": [
        ""
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GzYNcoV9Gawj"
      },
      "source": [
        "### Get validation data from ImageDataGenerator (5 Marks)\n",
        "- Give directory path\n",
        "- Give target size\n",
        "- Give batch_size\n",
        "- Specify classes, if you wish to use less number of classes you need to give class names in a list (Atleast 15 classes should be there)\n",
        "- Specify class_mode\n",
        "- Specify color_mode\n",
        "- Specify subset\n",
        "\n",
        "You can get details here\n",
        "https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-m9zfw0AHIma",
        "outputId": "7ce846de-466e-481c-bebc-9127f8521516",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "validation_generator = datagen.flow_from_directory(\n",
        "    '/content/drive/My Drive/Data - German Traffic Sign Recognition/Train', # same directory as training data\n",
        "    target_size=(128, 128),\n",
        "    batch_size=64,\n",
        "    classes=['20','21','22','23','24','25','26','27','28','29','30','31','32','33','34','35'],\n",
        "    class_mode='categorical',\n",
        "    subset='validation')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2194 images belonging to 16 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S2fXxJz1I_SV"
      },
      "source": [
        "### Define model (10 Marks)\n",
        "- Initialize a Sequential Model\n",
        "- Add Convolution, Maxpool, Dropout, Flatten & Dense layers according to your model architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fns3rEJ-DHQq"
      },
      "source": [
        "from tensorflow.keras.layers import Input, Dense\n",
        "from tensorflow.keras import Sequential, Model\n",
        "from tensorflow.keras.layers import BatchNormalization, Dropout, Flatten\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CpQB_OXheuvn"
      },
      "source": [
        "model = Sequential()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DfNKWsBNe3AR"
      },
      "source": [
        "model.add(Conv2D(64, (3, 3), activation='relu', input_shape=(128, 128, 3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(32, kernel_size=5, activation='relu'))\n",
        "model.add(MaxPooling2D(2, 2))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Conv2D(64, kernel_size=5, activation='relu'))\n",
        "model.add(MaxPooling2D(2, 2))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Flatten())\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(64, activation='relu')) \n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(16, activation='softmax'))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRs36YJgJvI0"
      },
      "source": [
        "### Compile the model (5 Marks)\n",
        "- Specify optimizer, loss & metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jvgO3JPvDQpL"
      },
      "source": [
        "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_Q6ihfUJ6Hm"
      },
      "source": [
        "### Get model summary (3 Marks)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3Sxnbo-lhfV",
        "outputId": "ad8f1886-a05c-4b17-cf10-4ab7caa5cbb7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 126, 126, 64)      1792      \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 126, 126, 64)      256       \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 122, 122, 32)      51232     \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 61, 61, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 61, 61, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 57, 57, 64)        51264     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 28, 28, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 28, 28, 64)        256       \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 28, 28, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 50176)             0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 50176)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 64)                3211328   \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 64)                256       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 16)                1040      \n",
            "=================================================================\n",
            "Total params: 3,317,424\n",
            "Trainable params: 3,317,040\n",
            "Non-trainable params: 384\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4mK8GNxFJ9vB"
      },
      "source": [
        "### Fit the model (5 Marks)\n",
        "- Specify epochs\n",
        "- Specify batch_size\n",
        "- Give validation_data\n",
        "- Validation accuracy should be more than 90%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9SLjprPDDYOs",
        "outputId": "af86e3bc-059a-4190-9986-e3b28f8e15b4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "history = model.fit(train_generator, steps_per_epoch=train_generator.samples // 64, validation_data=validation_generator, validation_steps=validation_generator.samples // 64, epochs=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/image_data_generator.py:720: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
            "  warnings.warn('This ImageDataGenerator specifies '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " 20/103 [====>.........................] - ETA: 15:48 - loss: 1.5647 - accuracy: 0.5156"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "diNbnH_dKO8J"
      },
      "source": [
        "### Draw plots (5 Marks)\n",
        "- Plot training accuracy and validation accuracy with respect to epochs\n",
        "- Plot training loss and validation loss with respect to epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8uoIPTssDofN",
        "outputId": "89107e0c-b857-4369-a957-19ce796a402f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        }
      },
      "source": [
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-6cd13d6a221b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izw92WsjqtEA"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TXeibTPdU9iI"
      },
      "source": [
        "## Future work (ungraded)\n",
        "- Try to apply transfer learning and see if you can improve the performance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dt1a3ayrVKoX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}